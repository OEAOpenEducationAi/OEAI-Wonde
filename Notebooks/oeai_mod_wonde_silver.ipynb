{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "%run oeai_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# CHANGE VALUES FOR YOUR KEY VAULT\r\n",
        "keyvault = \"kv-oea-oeai\"  \r\n",
        "keyvault_linked_service = \"LS_KeyVault\"  \r\n",
        "\r\n",
        "# Synapse OEA environment paths\r\n",
        "bronze_path = oeai.get_secret(spark, \"wonde-bronze\", keyvault_linked_service, keyvault)\r\n",
        "silver_path = oeai.get_secret(spark, \"wonde-silver\", keyvault_linked_service, keyvault)\r\n",
        "gold_path = oeai.get_secret(spark, \"gold-path\", keyvault_linked_service, keyvault)\r\n",
        "school_ids_secret = oeai.get_secret(spark, \"school-ids\", keyvault_linked_service, keyvault)\r\n",
        "subdirectories = school_ids_secret.split(\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Define the mapping between JSON files and desired Delta table names\r\n",
        "delta_table_name_mapping = {\r\n",
        "    \"schools.json\": \"dim_Organisation\",\r\n",
        "    \"students.json\": \"dim_Student\",\r\n",
        "    \"students_extended.json\": \"dim_StudentExtended\",\r\n",
        "    \"students_education.json\": \"\",\r\n",
        "    \"attendance-summaries.json\": \"fact_AttendanceSummary\",\r\n",
        "    \"attendancesession.json\": \"fact_AttendanceSession\",\r\n",
        "    \"behaviours_students.json\": \"fact_Behaviour\",\r\n",
        "    \"exclusions.json\": \"fact_Exclusion\",\r\n",
        "    \"achievements_students.json\": \"fact_Achievement\",\r\n",
        "    \"subjects.json\":\"dim_Subject\",\r\n",
        "    \"classes.json\":\"\",\r\n",
        "    \"groups.json\":\"dim_StudentGroup\"\r\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "column_mappings = {\r\n",
        "    \"schools.json\": {\r\n",
        "        # drops\r\n",
        "        \"timezone\": \"drop\", \r\n",
        "        \"mis\": \"drop\",\r\n",
        "        \"address_address_line_1\": \"drop\",\r\n",
        "        \"address_address_line_2\": \"drop\",\r\n",
        "        \"address_address_town\": \"drop\",\r\n",
        "        \"address_address_postcode\": \"drop\",\r\n",
        "        \"address_address_country_code\": \"drop\",\r\n",
        "        \"address_address_country_name\": \"drop\",\r\n",
        "        \"extended_allows_writeback\": \"drop\",\r\n",
        "        \"extended_has_timetables\": \"drop\",\r\n",
        "        \"extended_has_lesson_attendance\": \"drop\",\r\n",
        "        \"extended_audit_approved_at_date\": \"drop\",\r\n",
        "        \"extended_audit_approved_at_timezone_type\": \"drop\",\r\n",
        "        \"extended_audit_approved_at_timezone\": \"drop\",\r\n",
        "        \"region_code\": \"drop\",\r\n",
        "        \"region_domain\": \"drop\",\r\n",
        "        \"region_school_url\": \"drop\",\r\n",
        "        \"region_identifiers_la_code\": \"drop\",\r\n",
        "        \"region_identifiers_establishment_number\": \"drop\",\r\n",
        "        \"region_identifiers_urn\": \"drop\",\r\n",
        "        \"school_id\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"id\": {\"new_name\": \"external_id\"}, \r\n",
        "        \"name\": {\"new_name\": \"Organisation_Name\"},  \r\n",
        "        \"establishment_number\": {\"new_name\": \"Establishment_Number\"},  \r\n",
        "        \"urn\": {\"new_name\": \"URN\"},\r\n",
        "        \"la_code\": {\"new_name\": \"LA_Code\"},\r\n",
        "        \"phase_of_education\": {\"new_name\": \"Organisation_Type\"},\r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",  \r\n",
        "            \"addresskey\": \"\",  \r\n",
        "            \"UKPRN\": \"\",\r\n",
        "            \"Organisation_Status\": \"Active\",\r\n",
        "            \"last_updated\": \"\",\r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"students.json\": {\r\n",
        "        # drops\r\n",
        "        \"created_at\": \"drop\",\r\n",
        "        \"created_at_date\": \"drop\",\r\n",
        "        \"created_at_timezone\": \"drop\",\r\n",
        "        \"created_at_timezone_type\": \"drop\",\r\n",
        "        \"date_of_birth_timezone\": \"drop\",\r\n",
        "        \"date_of_birth_timezone_type\": \"drop\",\r\n",
        "        \"initials\": \"drop\",\r\n",
        "        \"mis_id\": \"drop\",\r\n",
        "        \"restored_at_date\": \"drop\",\r\n",
        "        \"restored_at_timezone\": \"drop\",\r\n",
        "        \"restored_at_timezone_type\": \"drop\",\r\n",
        "        \"updated_at_date\": \"drop\",\r\n",
        "        \"updated_at_timezone\": \"drop\",\r\n",
        "        \"updated_at_timezone_type\": \"drop\",\r\n",
        "        \"upi\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"date_of_birth_date\": {\"new_name\": \"Date_Of_Birth\"}, \r\n",
        "        \"forename\": {\"new_name\": \"Forename\"}, \r\n",
        "        \"gender\": {\"new_name\": \"Gender\"}, \r\n",
        "        \"id\": {\"new_name\": \"student_id\"}, \r\n",
        "        \"legal_forename\": {\"new_name\": \"Legal_Forename\"}, \r\n",
        "        \"legal_surname\": {\"new_name\": \"Legal_Surname\"}, \r\n",
        "        \"middle_names\": {\"new_name\": \"Middle_Names\"}, \r\n",
        "        \"surname\": {\"new_name\": \"Surname\"}, \r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "            \"studentkey\": \"\",\r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"students_extended.json\": {\r\n",
        "        # drops\r\n",
        "        \"created_at\": \"drop\",\r\n",
        "        \"created_at_date\": \"drop\",\r\n",
        "        \"date_of_birth_timezone\": \"drop\",\r\n",
        "        \"date_of_birth_timezone_type\": \"drop\",\r\n",
        "        \"date_of_birth_date\": \"drop\",\r\n",
        "        \"forename\": \"drop\",\r\n",
        "        \"gender\": \"drop\",\r\n",
        "        \"initials\": \"drop\",\r\n",
        "        \"legal_forename\": \"drop\",\r\n",
        "        \"legal_surname\": \"drop\",\r\n",
        "        \"middle_names\": \"drop\",\r\n",
        "        \"restored_at_date\": \"drop\",\r\n",
        "        \"restored_at_timezone\": \"drop\",\r\n",
        "        \"restored_at_timezone_type\": \"drop\",\r\n",
        "        \"surname\": \"drop\",\r\n",
        "        \"updated_at\": \"drop\",\r\n",
        "        \"upi\": \"drop\",\r\n",
        "        \"mis_id\": \"drop\",\r\n",
        "        \"extended_details_data_fsm_review_date\": \"drop\",\r\n",
        "        \"extended_details_data_premium_pupil_notes\": \"drop\",\r\n",
        "        \"extended_details_data_boarding_status\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"extended_details_data_english_as_additional_language\": {\"new_name\": \"English_As_Additional_Language\"}, \r\n",
        "        \"extended_details_data_enrolment_status\": {\"new_name\": \"Enrolment_Status\"}, \r\n",
        "        \"extended_details_data_ethnicity\": {\"new_name\": \"Ethnicity\"}, \r\n",
        "        \"extended_details_data_ethnicity_code\": {\"new_name\": \"Ethnicity_Code\"}, \r\n",
        "        \"extended_details_data_ever_in_care\": {\"new_name\": \"Ever_In_Care\"}, \r\n",
        "        \"extended_details_data_first_language\": {\"new_name\": \"First_Language\"}, \r\n",
        "        \"extended_details_data_free_school_meals\": {\"new_name\": \"Free_School_Meals\"}, \r\n",
        "        \"extended_details_data_free_school_meals_6\": {\"new_name\": \"Free_School_Meals_6\"}, \r\n",
        "        \"extended_details_data_gifted_and_talented_status\": {\"new_name\": \"Gifted_And_Talented_Status\"}, \r\n",
        "        \"extended_details_data_in_lea_care\": {\"new_name\": \"In_LEA_Care\"}, \r\n",
        "        \"extended_details_data_premium_pupil_indicator\": {\"new_name\": \"Pupil_Premium_Indicator\"}, \r\n",
        "        \"extended_details_data_sen_status\": {\"new_name\": \"SEN_Status\"}, \r\n",
        "        \"extended_details_data_service_children_indicator\": {\"new_name\": \"Service_Child_Indicator\"}, \r\n",
        "        \"id\": {\"new_name\": \"student_id\"},    \r\n",
        "        \"extended_details_data_leaver_destination\": {\"new_name\": \"Leaver_Destination\"}, \r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "            \"studentextendedkey\": \"\",\r\n",
        "            \"studentkey\": \"\",\r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"students_education.json\": {\r\n",
        "        # drops\r\n",
        "        \"created_at\": \"drop\",\r\n",
        "        \"date_of_birth_date\": \"drop\",\r\n",
        "        \"date_of_birth_timezone\": \"drop\",\r\n",
        "        \"date_of_birth_timezone_type\": \"drop\",\r\n",
        "        \"education_details_data_admission_date_timezone\": \"drop\",\r\n",
        "        \"education_details_data_admission_date_timezone_type\": \"drop\",\r\n",
        "        \"education_details_data_learner_number\": \"drop\",\r\n",
        "        \"education_details_data_part_time\": \"drop\",\r\n",
        "        \"education_details_data_leaving_date_timezone\": \"drop\",\r\n",
        "        \"education_details_data_leaving_date_timezone_type\": \"drop\",\r\n",
        "        \"forename\": \"drop\",\r\n",
        "        \"gender\": \"drop\",\r\n",
        "        \"initials\": \"drop\",\r\n",
        "        \"legal_forename\": \"drop\",\r\n",
        "        \"legal_surname\": \"drop\",\r\n",
        "        \"middle_names\": \"drop\",\r\n",
        "        \"mis_id\": \"drop\",\r\n",
        "        \"restored_at_date\": \"drop\",\r\n",
        "        \"restored_at_timezone\": \"drop\",\r\n",
        "        \"restored_at_timezone_type\": \"drop\",\r\n",
        "        \"surname\": \"drop\",\r\n",
        "        \"updated_at\": \"drop\",\r\n",
        "        \"upi\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"education_details_data_admission_date_date\": {\"new_name\": \"Admission_Date\"}, \r\n",
        "        \"education_details_data_current_nc_year\": {\"new_name\": \"Current_Year\"}, \r\n",
        "        \"education_details_data_upn\": {\"new_name\": \"UPN\"}, \r\n",
        "        \"education_details_data_leaving_date_date\": {\"new_name\": \"Leaving_Date\"}, \r\n",
        "        \"id\": {\"new_name\": \"student_id\"}, \r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "            \"studenteducationkey\": \"\",\r\n",
        "            \"studentkey\": \"\",\r\n",
        "        }\r\n",
        "    },    \r\n",
        "    \"attendance-summaries.json\": {\r\n",
        "        # drops\r\n",
        "        \"created_at\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"approved_education_activity\": {\"new_name\": \"Approved_Education_Activity\"}, \r\n",
        "        \"attendance_not_required\": {\"new_name\": \"Attendance_Not_Required\"}, \r\n",
        "        \"authorised_absences\": {\"new_name\": \"Authorised_Absences\"}, \r\n",
        "        \"id\": {\"new_name\": \"external_id\"}, \r\n",
        "        \"late_after_registration\": {\"new_name\": \"Late_After_Registration\"}, \r\n",
        "        \"late_before_registration\": {\"new_name\": \"Late_Before_Registration\"}, \r\n",
        "        \"missing_marks\": {\"new_name\": \"Missing_marks\"}, \r\n",
        "        \"possible_marks\": {\"new_name\": \"Possible_marks\"}, \r\n",
        "        \"present\": {\"new_name\": \"Present\"}, \r\n",
        "        \"unauthorized_absences\": {\"new_name\": \"Unauthorised_Absences\"}, \r\n",
        "        \"unexplained_absences\": {\"new_name\": \"Unexplained_Absences\"}, \r\n",
        "        \"updated_at\": {\"new_name\": \"last_updated\"}, \r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "            \"attendancesummarykey\": \"\",\r\n",
        "            \"studentkey\": \"\",\r\n",
        "            \"Attendance_Mark_String\": \"\",\r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"behaviours_students.json\": {\r\n",
        "        # drops\r\n",
        "        \"created_at_timezone\": \"drop\",\r\n",
        "        \"created_at_timezone_type\": \"drop\",\r\n",
        "        \"incident_date_timezone\": \"drop\",\r\n",
        "        \"incident_date_timezone_type\": \"drop\",\r\n",
        "        \"recorded_date_timezone\": \"drop\",\r\n",
        "        \"recorded_date_timezone_type\": \"drop\",\r\n",
        "        \"student_data_created_at_date\": \"drop\",\r\n",
        "        \"student_data_created_at_timezone\": \"drop\",\r\n",
        "        \"student_data_created_at_timezone_type\": \"drop\",\r\n",
        "        \"student_data_date_of_birth_date\": \"drop\",\r\n",
        "        \"student_data_date_of_birth_timezone\": \"drop\",\r\n",
        "        \"student_data_date_of_birth_timezone_type\": \"drop\",\r\n",
        "        \"student_data_forename\": \"drop\",\r\n",
        "        \"student_data_gender\": \"drop\",\r\n",
        "        \"student_data_initials\": \"drop\",\r\n",
        "        \"student_data_legal_forename\": \"drop\",\r\n",
        "        \"student_data_legal_surname\": \"drop\",\r\n",
        "        \"student_data_middle_names\": \"drop\",\r\n",
        "        \"student_data_restored_at_date\": \"drop\",\r\n",
        "        \"student_data_restored_at_timezone\": \"drop\",\r\n",
        "        \"student_data_restored_at_timezone_type\": \"drop\",\r\n",
        "        \"student_data_surname\": \"drop\",\r\n",
        "        \"student_data_updated_at_timezone\": \"drop\",\r\n",
        "        \"student_data_updated_at_timezone_type\": \"drop\",\r\n",
        "        \"student_data_meta_action\": \"drop\",\r\n",
        "        \"action\": \"drop\",\r\n",
        "        \"action_date_date\": \"drop\",\r\n",
        "        \"action_date_timezone\": \"drop\",\r\n",
        "        \"action_date_timezone_type\": \"drop\",\r\n",
        "        \"updated_at_timezone\": \"drop\",\r\n",
        "        \"updated_at_timezone_type\": \"drop\",\r\n",
        "        \"created_at_date\": \"drop\",\r\n",
        "        \"mis_id\": \"drop\",\r\n",
        "        \"parents_notified\": \"drop\",\r\n",
        "        \"recorded_date_date\": \"drop\",\r\n",
        "        \"student_data_meta_points\": \"drop\",\r\n",
        "        \"student_data_meta_role\": \"drop\",\r\n",
        "        \"student_data_mis_id\": \"drop\",\r\n",
        "        \"student_data_updated_at_date\": \"drop\",\r\n",
        "        \"student_data_upi\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"student_data_id\": {\"new_name\": \"student_id\"}, \r\n",
        "        \"updated_at_date\": {\"new_name\": \"last_updated\"}, \r\n",
        "        \"class\": {\"new_name\": \"Class\"}, \r\n",
        "        \"comment\": {\"new_name\": \"Comment\"}, \r\n",
        "        \"id\": {\"new_name\": \"external_id\"}, \r\n",
        "        \"incident_date_date\": {\"new_name\": \"Incident_Date\"}, \r\n",
        "        \"location\": {\"new_name\": \"Location\"}, \r\n",
        "        \"total_points\": {\"new_name\": \"Total_Points\"}, \r\n",
        "        \"points\": {\"new_name\": \"Points\"}, \r\n",
        "        \"subject\": {\"new_name\": \"Subject\"}, \r\n",
        "        \"type\": {\"new_name\": \"Type\"}, \r\n",
        "        \"status\": {\"new_name\": \"Status\"}, \r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "            \"behaviourkey\": \"\",\r\n",
        "            \"studentkey\": \"\",\r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"exclusions.json\": {\r\n",
        "        # drops\r\n",
        "        \"created_at\": \"drop\",\r\n",
        "        \"discipline_committee_date_date\": \"drop\",\r\n",
        "        \"discipline_committee_date_timezone\": \"drop\",\r\n",
        "        \"end_date_timezone\": \"drop\",\r\n",
        "        \"end_date_timezone_type\": \"drop\",\r\n",
        "        \"mis_id\": \"drop\",\r\n",
        "        \"start_date_timezone\": \"drop\",\r\n",
        "        \"start_date_timezone_type\": \"drop\",\r\n",
        "        \"student_data_created_at\": \"drop\",\r\n",
        "        \"student_data_date_of_birth_date\": \"drop\",\r\n",
        "        \"student_data_date_of_birth_timezone\": \"drop\",\r\n",
        "        \"student_data_date_of_birth_timezone_type\": \"drop\",\r\n",
        "        \"student_data_forename\": \"drop\",\r\n",
        "        \"student_data_gender\": \"drop\",\r\n",
        "        \"student_data_initials\": \"drop\",\r\n",
        "        \"student_data_legal_forename\": \"drop\",\r\n",
        "        \"student_data_legal_surname\": \"drop\",\r\n",
        "        \"student_data_mis_id\": \"drop\",\r\n",
        "        \"student_data_surname\": \"drop\",\r\n",
        "        \"student_data_updated_at\": \"drop\",\r\n",
        "        \"student_data_upi\": \"drop\",\r\n",
        "        \"student_data_restored_at_date\": \"drop\",\r\n",
        "        \"student_data_restored_at_timezone\": \"drop\",\r\n",
        "        \"student_data_restored_at_timezone_type\": \"drop\",\r\n",
        "        \"discipline_committee_date_timezone_type\": \"drop\",\r\n",
        "        \"discipline_committee_representation_made\": \"drop\",\r\n",
        "        \"student_data_middle_names\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"academic_year\": {\"new_name\": \"Academic_Year\"}, \r\n",
        "        \"agencies_involved\": {\"new_name\": \"Agencies_Involved\"}, \r\n",
        "        \"appeal_received\": {\"new_name\": \"Appeal_Received\"}, \r\n",
        "        \"comments\": {\"new_name\": \"Comments\"}, \r\n",
        "        \"end_date_date\": {\"new_name\": \"End_Date\"}, \r\n",
        "        \"end_session\": {\"new_name\": \"End_Session\"}, \r\n",
        "        \"id\": {\"new_name\": \"external_id\"}, \r\n",
        "        \"days\": {\"new_name\": \"Days\"}, \r\n",
        "        \"reason\": {\"new_name\": \"Reason\"}, \r\n",
        "        \"reason_code\": {\"new_name\": \"Reason_Code\"}, \r\n",
        "        \"sessions\": {\"new_name\": \"Sessions\"}, \r\n",
        "        \"start_date_date\": {\"new_name\": \"Start_Date\"}, \r\n",
        "        \"start_session\": {\"new_name\": \"Start_Session\"}, \r\n",
        "        \"student_data_id\": {\"new_name\": \"student_id\"},  \r\n",
        "        \"term\": {\"new_name\": \"Term\"}, \r\n",
        "        \"type\": {\"new_name\": \"Type\"}, \r\n",
        "        \"type_code\": {\"new_name\": \"Type_Code\"}, \r\n",
        "        \"updated_at\": {\"new_name\": \"last_updated\"}, \r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "            \"exclusionkey\": \"\",\r\n",
        "            \"studentkey\": \"\",\r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"achievements_students.json\": {\r\n",
        "\t\t# drops\r\n",
        "\t\t\"achievement_date_timezone\": \"drop\",\r\n",
        "\t\t\"achievement_date_timezone_type\": \"drop\",\r\n",
        "\t\t\"created_at_date\": \"drop\",\r\n",
        "\t\t\"created_at_timezone\": \"drop\",\r\n",
        "\t\t\"created_at_timezone_type\": \"drop\",\r\n",
        "\t\t\"mis_id\": \"drop\",\r\n",
        "\t\t\"parents_notified\": \"drop\",\r\n",
        "\t\t\"recorded_date_date\": \"drop\",\r\n",
        "\t\t\"recorded_date_timezone\": \"drop\",\r\n",
        "\t\t\"recorded_date_timezone_type\": \"drop\",\r\n",
        "\t\t\"student_data_created_at_date\": \"drop\",\r\n",
        "\t\t\"student_data_created_at_timezone\": \"drop\",\r\n",
        "\t\t\"student_data_created_at_timezone_type\": \"drop\",\r\n",
        "\t\t\"student_data_date_of_birth_date\": \"drop\",\r\n",
        "\t\t\"student_data_date_of_birth_timezone\": \"drop\",\r\n",
        "\t\t\"student_data_date_of_birth_timezone_type\": \"drop\",\r\n",
        "\t\t\"student_data_forename\": \"drop\",\r\n",
        "\t\t\"student_data_gender\": \"drop\",\r\n",
        "\t\t\"student_data_initials\": \"drop\",\r\n",
        "\t\t\"student_data_legal_forename\": \"drop\",\r\n",
        "\t\t\"student_data_legal_surname\": \"drop\",\r\n",
        "\t\t\"student_data_meta_points\": \"drop\",\r\n",
        "\t\t\"student_data_middle_names\": \"drop\",\r\n",
        "\t\t\"student_data_mis_id\": \"drop\",\r\n",
        "\t\t\"student_data_restored_at_date\": \"drop\",\r\n",
        "\t\t\"student_data_restored_at_timezone\": \"drop\",\r\n",
        "\t\t\"student_data_restored_at_timezone_type\": \"drop\",\r\n",
        "\t\t\"student_data_surname\": \"drop\",\r\n",
        "\t\t\"student_data_updated_at_date\": \"drop\",\r\n",
        "\t\t\"student_data_updated_at_timezone\": \"drop\",\r\n",
        "\t\t\"student_data_updated_at_timezone_type\": \"drop\",\r\n",
        "\t\t\"student_data_upi\": \"drop\",\r\n",
        "\t\t\"updated_at_timezone\": \"drop\",\r\n",
        "\t\t\"updated_at_timezone_type\": \"drop\",\r\n",
        "\t\t# Renames\r\n",
        "\t\t\"achievement_date_date\": {\"new_name\": \"Achievement_Date\"}, \r\n",
        "\t\t\"class\": {\"new_name\": \"Class\"}, \r\n",
        "\t\t\"comment\": {\"new_name\": \"Comment\"}, \r\n",
        "\t\t\"id\": {\"new_name\": \"external_id\"}, \r\n",
        "\t\t\"points\": {\"new_name\": \"Points\"}, \r\n",
        "\t\t\"student_data_id\": {\"new_name\": \"student_id\"}, \r\n",
        "\t\t\"subject\": {\"new_name\": \"Subject\"}, \r\n",
        "\t\t\"total_points\": {\"new_name\": \"Total_Points\"}, \r\n",
        "\t\t\"type\": {\"new_name\": \"Type\"}, \r\n",
        "\t\t\"updated_at_date\": {\"new_name\": \"last_updated\"}, \r\n",
        "\t\t# adds\r\n",
        "\t\t\"add_columns\": {\r\n",
        "\t\t\"organisationkey\": \"\",\r\n",
        "\t\t\"achievementkey\": \"\",\r\n",
        "        \"studentkey\": \"\",\r\n",
        "\t\t}\r\n",
        "\t},\r\n",
        "    \"subjects.json\": {\r\n",
        "        # drops\r\n",
        "        \"created_at\":\"drop\",\r\n",
        "        \"updated_at\":\"drop\",\r\n",
        "        \"mis_id\":\"drop\",\r\n",
        "        # Renames\r\n",
        "        \"code\": {\"new_name\": \"Subject_Code\"},\r\n",
        "        \"id\": {\"new_name\": \"external_id\"}, \r\n",
        "        \"name\": {\"new_name\": \"Subject_Name\"}, \r\n",
        "        \"subject\": {\"new_name\": \"Subject\"}, \r\n",
        "        \"active\": {\"new_name\": \"Active\"}, \r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "            \"subjectkey\":\"\"\r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"classes.json\": {\r\n",
        "        #drop\r\n",
        "        \"mis_id\":\"drop\",\r\n",
        "        \"created_at\":\"drop\",\r\n",
        "        \"updated_at\":\"drop\",\r\n",
        "        \"restored_at_date\":\"drop\",\r\n",
        "        \"restored_at_timezone\":\"drop\",\r\n",
        "        \"restored_at_timezone_type\":\"drop\",\r\n",
        "\r\n",
        "        # Renames\r\n",
        "        \"name\": {\"new_name\": \"Group_Name\"}, \r\n",
        "        \"description\": {\"new_name\": \"Group_Description\"}, \r\n",
        "        \"id\": {\"new_name\": \"external_id\"},\r\n",
        "        \"subject\": {\"new_name\": \"Subject_Id\"},\r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "             \"studentgroupkey\": \"\",\r\n",
        "             \"Group_Type\":\"\",\r\n",
        "             \"Group_Code\":\"\"\r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"groups.json\": {\r\n",
        "        #drop\r\n",
        "        \"mis_id\":\"drop\",\r\n",
        "        \"created_at\":\"drop\",\r\n",
        "        \"updated_at\":\"drop\",\r\n",
        "        \"restored_at_date\":\"drop\",\r\n",
        "        \"restored_at_timezone\":\"drop\",\r\n",
        "        \"restored_at_timezone_type\":\"drop\",\r\n",
        "\r\n",
        "        # Renames\r\n",
        "        \"name\": {\"new_name\": \"Group_Name\"}, \r\n",
        "        \"code\": {\"new_name\": \"Group_Code\"}, \r\n",
        "        \"id\": {\"new_name\": \"external_id\"},\r\n",
        "        \"description\": {\"new_name\": \"Group_Description\"}, \r\n",
        "        \"type\": {\"new_name\": \"Group_Type\"},\r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "             \"studentgroupkey\": \"\",\r\n",
        "             \"Subject_Id\":\"\"\r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"attendancesession.json\": {\r\n",
        "        # drops\r\n",
        "        \"date_timezone\": \"drop\",\r\n",
        "        \"date_timezone_type\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"comment\": {\"new_name\": \"Comment\"}, \r\n",
        "        \"date_date\": {\"new_name\": \"Date\"}, \r\n",
        "        \"employee\": {\"new_name\": \"staff_id\"}, \r\n",
        "        \"id\": {\"new_name\": \"external_id\"}, \r\n",
        "        \"session\": {\"new_name\": \"Session\"}, \r\n",
        "        \"student\": {\"new_name\": \"student_id\"}, \r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "            \"attendancesessionkey\": \"\",\r\n",
        "            \"studentkey\": \"\",\r\n",
        "        }\r\n",
        "    },\r\n",
        "}\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Dictionary to hold dataframes for each json file\r\n",
        "json_dfs = {}\r\n",
        "temp_dfs = {}\r\n",
        "all_columns = {}\r\n",
        "'''\r\n",
        "    This code is to loop through each directory and compile all the individual schools jsons into\r\n",
        "    a single json per endpoint.\r\n",
        "\r\n",
        "    It creates json_dfs - a dictionary of the aggregated json files\r\n",
        "'''\r\n",
        "for subdir in subdirectories:\r\n",
        "    school_dir = f\"{bronze_path}{subdir}/\"\r\n",
        "\r\n",
        "    # Consider only JSON files that are in your mapping\r\n",
        "    json_dirs = list(delta_table_name_mapping.keys())\r\n",
        "\r\n",
        "    #print(list(delta_table_name_mapping.keys()))\r\n",
        "    for json_dir in json_dirs:\r\n",
        "        json_dir_path = f\"{school_dir}{json_dir}/\"\r\n",
        "        try:\r\n",
        "            temp_df = spark.read.json(json_dir_path)\r\n",
        "            temp_df = temp_df.withColumn(\"school_id\", lit(subdir))\r\n",
        "\r\n",
        "            # Update the set of columns for the json_dir\r\n",
        "            all_columns.setdefault(json_dir, set()).update(temp_df.columns)\r\n",
        "\r\n",
        "            # Check if json_dir already exists in temp_dfs dictionary\r\n",
        "            if json_dir in temp_dfs:\r\n",
        "                # Align the schema of temp_df with existing DataFrame in temp_dfs\r\n",
        "                existing_columns = all_columns[json_dir]\r\n",
        "                temp_df = add_missing_columns(temp_df, existing_columns)\r\n",
        "                existing_df = add_missing_columns(temp_dfs[json_dir], temp_df.columns)\r\n",
        "                # Perform the union operation\r\n",
        "                try:\r\n",
        "                    temp_df = match_column_types(existing_df, temp_df)\r\n",
        "                    temp_dfs[json_dir] = existing_df[sorted(existing_df.columns)].unionByName(temp_df[sorted(temp_df.columns)])\r\n",
        "                except Exception as e:\r\n",
        "                    print(\"An unexpected error occurred:\", e)\r\n",
        "            else:\r\n",
        "                # If not, simply assign temp_df to temp_dfs[json_dir]\r\n",
        "                temp_dfs[json_dir] = temp_df\r\n",
        "        except AnalysisException as e:\r\n",
        "            print(f\"Path does not exist: {json_dir_path}, skipping...\")\r\n",
        "            continue\r\n",
        "        except Exception as e:\r\n",
        "            print(f\"An unexpected error occurred while processing {json_dir_path}: {e}\")\r\n",
        "            continue\r\n",
        "# Assign the final json_dfs outside the loops\r\n",
        "json_dfs = temp_dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "for json_name, df in json_dfs.items():\r\n",
        "    if json_name in column_mappings:\r\n",
        "        df = apply_column_mappings(df, column_mappings[json_name])\r\n",
        "        json_dfs[json_name] = df  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# List of jobs next to get the dimensions in the correct schema.\r\n",
        "\r\n",
        "# dim_Student requires UPN and Current_Year from StudentEducation\r\n",
        "# Access the DataFrames\r\n",
        "df_joined = []\r\n",
        "df_student = json_dfs['students.json']\r\n",
        "df_student_education = json_dfs['students_education.json']\r\n",
        "\r\n",
        "df_joined = df_student.join(\r\n",
        "    df_student_education.select('unique_key', 'UPN', 'Current_Year'),\r\n",
        "    on='unique_key',  # column name to join on, which must be present in both DataFrames\r\n",
        "    how='inner'  # you can also use 'left', 'right', or 'outer' as needed\r\n",
        ")\r\n",
        "json_dfs['students.json'] = df_joined\r\n",
        "\r\n",
        "#  dim_StudentExtended requires Admission_Date from StudentEducation\r\n",
        "df_joined = []\r\n",
        "df_student_extended = json_dfs['students_extended.json']\r\n",
        "df_student_education = json_dfs['students_education.json']\r\n",
        "\r\n",
        "try:\r\n",
        "    df_joined = df_student_extended.join(\r\n",
        "        df_student_education.select('unique_key', 'Admission_Date', 'Leaving_Date'),\r\n",
        "        on='unique_key',  # column name to join on, which must be present in both DataFrames\r\n",
        "        how='inner'  # you can also use 'left', 'right', or 'outer' as needed\r\n",
        "    )\r\n",
        "    json_dfs['students_extended.json'] = df_joined\r\n",
        "except:\r\n",
        "    df_joined = df_student_extended.join(\r\n",
        "        df_student_education.select('unique_key', 'Admission_Date'),\r\n",
        "        on='unique_key',  # column name to join on, which must be present in both DataFrames\r\n",
        "        how='inner'  # you can also use 'left', 'right', or 'outer' as needed\r\n",
        "    )\r\n",
        "    json_dfs['students_extended.json'] = df_joined\r\n",
        "#json_dfs['students_extended.json'].printSchema()\r\n",
        "\r\n",
        "#class and group union\r\n",
        "#df_classes = json_dfs['classes.json']\r\n",
        "#df_groups = json_dfs['groups.json']\r\n",
        "#df_classes.printSchema()\r\n",
        "#df_groups.printSchema()\r\n",
        "#df_union = df_classes.unionByName(df_groups)\r\n",
        "\r\n",
        "#json_dfs['groups.json'] = df_union\r\n",
        "\r\n",
        "df_attendance_summary = json_dfs['attendance-summaries.json']\r\n",
        "\r\n",
        "# Convert string columns to integer\r\n",
        "df_attendance_summary = df_attendance_summary.withColumn(\"Present\", col(\"Present\").cast(\"int\"))\r\n",
        "df_attendance_summary = df_attendance_summary.withColumn(\"Approved_Education_Activity\", col(\"Approved_Education_Activity\").cast(\"int\"))\r\n",
        "df_attendance_summary = df_attendance_summary.withColumn(\"Possible_marks\", col(\"Possible_marks\").cast(\"int\"))\r\n",
        "\r\n",
        "# Calculate Percentage_Attendance and format to two decimal places\r\n",
        "df_attendance_summary = df_attendance_summary.withColumn(\"Percentage_Attendance\", \r\n",
        "                   ((col(\"Present\") + col(\"Approved_Education_Activity\")) / col(\"Possible_marks\")).cast(DecimalType(10, 4)))\r\n",
        "# Calculate Percentage_Auth and format to two decimal places\r\n",
        "df_attendance_summary = df_attendance_summary.withColumn(\"Percentage_Authorised_Absence\", \r\n",
        "                   ((col(\"Authorised_Absences\")) / col(\"Possible_marks\")).cast(DecimalType(10, 4)))\r\n",
        "# Calculate Percentage_UnAuth and format to two decimal places\r\n",
        "df_attendance_summary = df_attendance_summary.withColumn(\"Percentage_Unauthorised_Absence\", \r\n",
        "                   ((col(\"Unauthorized_Absences\")) / col(\"Possible_marks\")).cast(DecimalType(10, 4)))\r\n",
        "# Calculate Percentage_Unexp and format to two decimal places\r\n",
        "df_attendance_summary = df_attendance_summary.withColumn(\"Percentage_Unexplained_Absence\", \r\n",
        "                   ((col(\"Unexplained_Absences\")) / col(\"Possible_marks\")).cast(DecimalType(10, 4)))\r\n",
        "\r\n",
        "df_attendance_summary = df_attendance_summary.withColumn(\r\n",
        "    \"Is_Persistently_Absent\",\r\n",
        "    when(col(\"Percentage_Attendance\") < 0.9, 1).otherwise(0)\r\n",
        ")                   \r\n",
        "\r\n",
        "df_attendance_summary = df_attendance_summary.withColumn(\r\n",
        "    \"Is_Severely_Absent\",\r\n",
        "    when(col(\"Percentage_Attendance\") < 0.5, 1).otherwise(0)\r\n",
        ")                   \r\n",
        "\r\n",
        "json_dfs['attendance-summaries.json'] = df_attendance_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Process each DataFrame and upsert it to the silver_path\r\n",
        "for json_name, df in json_dfs.items():\r\n",
        "    \r\n",
        "    if json_name in delta_table_name_mapping and delta_table_name_mapping[json_name] != \"\":\r\n",
        "        # Get the Delta table name from the mapping\r\n",
        "        delta_table_name = delta_table_name_mapping[json_name]\r\n",
        "        silver_table_path = f\"{silver_path}/{delta_table_name}\"\r\n",
        "        uuid_column_name = get_uuid_column_name(delta_table_name)\r\n",
        "\r\n",
        "        # Define the unique key column name\r\n",
        "        unique_key_column = \"unique_key\"  \r\n",
        "\r\n",
        "        if delta_table_name == \"dim_Organisation\":\r\n",
        "            if DeltaTable.isDeltaTable(spark, silver_table_path):\r\n",
        "                delta_table = DeltaTable.forPath(spark, silver_table_path)\r\n",
        "                \r\n",
        "                # Alias the Delta table as 'target' and rename 'organisationkey' to 'target_organisationkey'\r\n",
        "                target_df = delta_table.toDF().select(unique_key_column, col(\"organisationkey\").alias(\"target_organisationkey\"))\r\n",
        "                \r\n",
        "                # Alias the source DataFrame as 'source'\r\n",
        "                source_df = df.alias(\"source\")\r\n",
        "                \r\n",
        "                # Perform a left join to find non-matched records\r\n",
        "                df_with_keys = source_df.join(\r\n",
        "                    target_df,\r\n",
        "                    source_df[unique_key_column] == target_df[unique_key_column],\r\n",
        "                    how=\"left\"\r\n",
        "                ).select(\r\n",
        "                    # Select all columns from 'source' EXCEPT 'organisationkey' if it exists\r\n",
        "                    *[source_df[col].alias(col) for col in source_df.columns if col != \"organisationkey\"],\r\n",
        "                    # Coalesce to get 'organisationkey' from 'target' if it exists, or generate a new one\r\n",
        "                    coalesce(col(\"target_organisationkey\"), expr(\"uuid()\")).alias(\"organisationkey\")\r\n",
        "                )\r\n",
        "                \r\n",
        "                # Now perform the merge operation\r\n",
        "                delta_table.alias(\"target\").merge(\r\n",
        "                    df_with_keys.alias(\"source\"),\r\n",
        "                    f\"target.{unique_key_column} = source.{unique_key_column}\"\r\n",
        "                ).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\r\n",
        "                \r\n",
        "            else:\r\n",
        "                # If the table does not exist, create it by writing the current DataFrame\r\n",
        "                # First, add a column for the organisationkey for all records since this is a new table\r\n",
        "                df = df.withColumn(\"organisationkey\", expr(\"uuid()\"))\r\n",
        "                df.write.format(\"delta\").mode(\"overwrite\").save(silver_table_path)\r\n",
        "        else:\r\n",
        "            # Process student table before all others:\r\n",
        "            if delta_table_name == \"dim_Student\":\r\n",
        "                if DeltaTable.isDeltaTable(spark, silver_table_path):\r\n",
        "                    delta_table = DeltaTable.forPath(spark, silver_table_path)\r\n",
        "                    try:\r\n",
        "                        update_columns = {col: f\"source.{col}\" for col in df.columns if col not in ['organisationkey', uuid_column_name]}\r\n",
        "                        delta_table.alias(\"target\").merge(\r\n",
        "                            df.alias(\"source\"),\r\n",
        "                            f\"target.{unique_key_column} = source.{unique_key_column}\"\r\n",
        "                        ).whenMatchedUpdate(set=update_columns  # Use the dictionary of columns to update\r\n",
        "                        ).whenNotMatchedInsertAll().execute()\r\n",
        "                    except Exception as e:\r\n",
        "                        print(delta_table_name)\r\n",
        "                        df.printSchema()\r\n",
        "                        print(e)\r\n",
        "                else:\r\n",
        "                    # If the table does not exist, create it by writing the current DataFrame\r\n",
        "                    df = df.withColumn(uuid_column_name, expr(\"uuid()\"))\r\n",
        "                    # Load the dim_Organisation table to get the existing mappings\r\n",
        "                    dim_org_df = spark.read.format(\"delta\").load(f\"{silver_path}/dim_Organisation\").select(\"external_id\", \"organisationkey\")\r\n",
        "                    # Perform a left join to find existing organisation keys\r\n",
        "                    df_joined = df.alias(\"source\").join(\r\n",
        "                        dim_org_df.alias(\"dim\"),\r\n",
        "                        col(\"source.school_id\") == col(\"dim.external_id\"),\r\n",
        "                        \"left\"\r\n",
        "                    )\r\n",
        "                    # Select all columns from df and only the 'organisationkey' from the dim_Organisation\r\n",
        "                    df_with_keys = df_joined.select(\"source.*\", col(\"dim.organisationkey\").alias(\"dim_organisationkey\"))\r\n",
        "                    # Fill in the missing keys with UUIDs\r\n",
        "                    df_complete = df_with_keys.withColumn(\r\n",
        "                        \"organisationkey\",\r\n",
        "                        when(col(\"dim_organisationkey\").isNull(), expr(\"uuid()\")).otherwise(col(\"dim_organisationkey\"))\r\n",
        "                    )\r\n",
        "                    # Drop the 'dim_organisationkey' as it is no longer needed\r\n",
        "                    df_final = df_complete.drop(\"dim_organisationkey\")\r\n",
        "                    df_final.write.format(\"delta\").mode(\"overwrite\").save(silver_table_path)\r\n",
        "            else: # if not the organisation or student table         \r\n",
        "                \r\n",
        "                if ('studentkey' in df.columns) and (delta_table_name != \"dim_Student\"):\r\n",
        "                    # ------------------------------\r\n",
        "                    # First, get the organisationkey\r\n",
        "                    # ------------------------------\r\n",
        "                    # Read the dim_Organisation table\r\n",
        "                    dim_org_df = spark.read.format(\"delta\").load(f\"{silver_path}/dim_Organisation\").select(\"external_id\", \"organisationkey\")\r\n",
        "                    \r\n",
        "                    df = df.drop(\"organisationkey\")\r\n",
        "\r\n",
        "                    # Perform a left join to find existing organisation keys\r\n",
        "                    df_joined = df.alias(\"source\").join(\r\n",
        "                        dim_org_df.alias(\"dim\"),\r\n",
        "                        col(\"source.school_id\") == col(\"dim.external_id\"),\r\n",
        "                        \"left\"\r\n",
        "                    )\r\n",
        "\r\n",
        "                    # df_joined = df.drop(\"external_id\")\r\n",
        "\r\n",
        "                    # Select all columns from df (source) and only the 'organisationkey' from dim_Organisation (dim)\r\n",
        "                    # Alias the dim_Organisation's organisationkey to avoid ambiguity\r\n",
        "                    \r\n",
        "                    df_with_orgkey = df_joined.select(\r\n",
        "                        *[col(f\"source.{col_name}\") for col_name in df.columns],\r\n",
        "                        col(\"dim.organisationkey\")\r\n",
        "                    )\r\n",
        "\r\n",
        "                    # --------------------------\r\n",
        "                    # second, get the studentkey\r\n",
        "                    # --------------------------\r\n",
        "                    \r\n",
        "                    dim_student_df = spark.read.format(\"delta\").load(f\"{silver_path}/dim_Student\").select(\"student_id\", \"organisationkey\", \"studentkey\")\r\n",
        "                    # Rename the 'studentkey' column from dim_student_df to avoid ambiguity\r\n",
        "                    dim_student_df = dim_student_df.withColumnRenamed(\"studentkey\", \"dim_studentkey\")\r\n",
        "                    \r\n",
        "                    # Perform a left join\r\n",
        "                    df_studjoined = df_with_orgkey.alias(\"source\").join(\r\n",
        "                        dim_student_df.alias(\"dim\"),\r\n",
        "                        (trim(lower(col(\"source.student_id\"))) == trim(lower(col(\"dim.student_id\")))) &\r\n",
        "                        (trim(lower(col(\"source.organisationkey\"))) == trim(lower(col(\"dim.organisationkey\")))),\r\n",
        "                        \"left\"\r\n",
        "                    )\r\n",
        "                    \r\n",
        "                    # Use when() to decide which studentkey to keep\r\n",
        "                    df_both_keys = df_studjoined.withColumn(\"studentkey\", \r\n",
        "                                            when(col(\"dim.dim_studentkey\").isNull(), col(\"source.studentkey\"))\r\n",
        "                                            .otherwise(col(\"dim.dim_studentkey\"))\r\n",
        "                                            ) \\\r\n",
        "                                .drop(\"dim.dim_studentkey\") \\\r\n",
        "                                .select(\"source.*\", \"studentkey\")\r\n",
        "\r\n",
        "                    df = df_both_keys\r\n",
        "\r\n",
        "                    # debug, show 20 records\r\n",
        "                    #df.filter((col(\"studentkey\").isNotNull()) & (col(\"studentkey\") != \"\")).select(\"studentkey\").show(n=20, truncate=False)\r\n",
        "\r\n",
        "                # -------------------------------------------------------------------\r\n",
        "                # Now that any table with student_id in it has studentkey continue...\r\n",
        "                # -------------------------------------------------------------------\r\n",
        "\r\n",
        "                # Set the update columns to update everything other than organisationkey and the unique_key\r\n",
        "                update_columns = {col: f\"source.{col}\" for col in df.columns if col not in ['organisationkey', uuid_column_name]}\r\n",
        "                # print(update_columns)\r\n",
        "\r\n",
        "                if DeltaTable.isDeltaTable(spark, silver_table_path):\r\n",
        "                    delta_table = DeltaTable.forPath(spark, silver_table_path)\r\n",
        "                    try:\r\n",
        "                        delta_table.alias(\"target\").merge(\r\n",
        "                            df.alias(\"source\"),\r\n",
        "                            f\"target.{unique_key_column} = source.{unique_key_column}\"\r\n",
        "                        ).whenMatchedUpdate(set=update_columns  # Use the dictionary of columns to update\r\n",
        "                        ).whenNotMatchedInsertAll().execute()\r\n",
        "\r\n",
        "                    except Exception as e:\r\n",
        "                        print(delta_table_name)\r\n",
        "                        df.printSchema()\r\n",
        "                        print(e)\r\n",
        "                    \r\n",
        "                else:\r\n",
        "                    # If the table does not exist, create it by writing the current DataFrame\r\n",
        "                    # First, generate a UUID for all records in the new UUID column\r\n",
        "                    df = df.withColumn(uuid_column_name, expr(\"uuid()\"))\r\n",
        "\r\n",
        "                    if ('studentkey' not in df.columns): # because we have already added organisationkey to that\r\n",
        "                \r\n",
        "                        # Load the dim_Organisation table to get the existing mappings\r\n",
        "                        dim_org_df = spark.read.format(\"delta\").load(f\"{silver_path}/dim_Organisation\").select(\"external_id\", \"organisationkey\")\r\n",
        "\r\n",
        "                        # Perform a left join to find existing organisation keys\r\n",
        "                        df_joined = df.alias(\"source\").join(\r\n",
        "                            dim_org_df.alias(\"dim\"),\r\n",
        "                            col(\"source.school_id\") == col(\"dim.external_id\"),\r\n",
        "                            \"left\"\r\n",
        "                        )\r\n",
        "\r\n",
        "                        # Select all columns from df and only the 'organisationkey' from the dim_Organisation\r\n",
        "                        # Alias the dim_Organisation's organisationkey to avoid ambiguity\r\n",
        "                        df_with_keys = df_joined.select(\"source.*\", col(\"dim.organisationkey\").alias(\"dim_organisationkey\"))\r\n",
        "                        df_with_keys.printSchema()\r\n",
        "\r\n",
        "                        # Fill in the missing keys with UUIDs\r\n",
        "                        # Ensure to use the aliased column name 'dim_organisationkey' to avoid ambiguity\r\n",
        "                        df_complete = df_with_keys.withColumn(\r\n",
        "                            \"organisationkey\",\r\n",
        "                            when(col(\"dim_organisationkey\").isNull(), expr(\"uuid()\")).otherwise(col(\"dim_organisationkey\"))\r\n",
        "                        )\r\n",
        "\r\n",
        "                        # Drop the 'dim_organisationkey' as it is no longer needed\r\n",
        "                        df = df_complete.drop(\"dim_organisationkey\")\r\n",
        "\r\n",
        "\r\n",
        "                    # debug, show 20 records\r\n",
        "                    df.show(n=20, truncate=False)\r\n",
        "\r\n",
        "                    df.write.format(\"delta\").mode(\"overwrite\").save(silver_table_path)"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}